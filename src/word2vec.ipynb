{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47f5184d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from io import StringIO\n",
    "import datetime\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "now = datetime.datetime.now().strftime(format=\"%Y-%m-%d_%H-%M\")\n",
    "\n",
    "# Chargement donnees\n",
    "df_train = pd.read_csv('../data/train-sep.csv')\n",
    "\n",
    "# Separation des donnees et pretraitement\n",
    "X_train_raw = df_train['titre']\n",
    "y_train_raw = df_train['type']\n",
    "\n",
    "# Preprocess sur les donnees de trainentraines\n",
    "preprocessed_text_train = [simple_preprocess(sentence, min_len = 1) for sentence in X_train_raw]\n",
    "\n",
    "# Train modele Word2Vec \n",
    "model = Word2Vec(sentences = preprocessed_text_train, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Transformation donnees à plongments Word2Vec \n",
    "X_train = np.array([np.mean([model.wv[word] for word in words if word in model.wv] or [np.zeros(100)], axis=0) for words in preprocessed_text_train])\n",
    "\n",
    "# Encodage des labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train_raw)\n",
    "\n",
    "# Chargement des donnees de test\n",
    "df_test = pd.read_csv('../data/test.csv')\n",
    "X_test = df_test['titre']\n",
    "\n",
    "# Preprocess sur les donnees de tests\n",
    "preprocessed_text_test = [simple_preprocess(sentence, min_len=1) for sentence in X_test]\n",
    "\n",
    "# Transformation donnees de texte test en plongement Word2Vec\n",
    "X_test_emb = np.array([model.wv[word] for sentence in preprocessed_text_test for word in sentence if word in model.wv])\n",
    "\n",
    "# Train SVM classifier\n",
    "classifier = SVC(kernel='linear')\n",
    "classifier.fit(X_train, y_train_encoded)\n",
    "\n",
    "# Prediction encode de donnees de test\n",
    "y_pred_encoded = classifier.predict(X_test_emb)\n",
    "y_pred_encoded = y_pred_encoded[:len(df_test)]\n",
    "\n",
    "# Decodage de predictions\n",
    "y_pred = label_encoder.inverse_transform(y_pred_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2ef5238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Titre Categorie Prédite\n",
      "0                          Roulé à la confiture de lait    Plat principal\n",
      "1                                Croissants aux amandes    Plat principal\n",
      "2     Quinoa Phileas (aux légumes croquants et sauci...    Plat principal\n",
      "3                   Magret de canard à la crème de mûre    Plat principal\n",
      "4     St-Jacques a la sauce aux huitres et aux asperges    Plat principal\n",
      "...                                                 ...               ...\n",
      "1383             Galettes de pommes de terre aux navets    Plat principal\n",
      "1384  Terrine d'aubergines au thon de Nadine (4ème r...           Dessert\n",
      "1385              Gateau aux amandes et fleur d'oranger    Plat principal\n",
      "1386                               Cailles au vin rouge    Plat principal\n",
      "1387  Gratin de pâtes au boeuf, courgettes et mascar...    Plat principal\n",
      "\n",
      "[1388 rows x 2 columns]\n",
      "Précision du modèle : 0.4452449567723343 \n",
      " -----------------------------\n",
      "\n",
      "Rapport de classification :\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       Dessert       0.22      0.05      0.08       407\n",
      "        Entrée       0.00      0.00      0.00       337\n",
      "Plat principal       0.46      0.93      0.62       644\n",
      "\n",
      "      accuracy                           0.45      1388\n",
      "     macro avg       0.23      0.33      0.23      1388\n",
      "  weighted avg       0.28      0.45      0.31      1388\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leon/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/leon/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/leon/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Création d'un DataFrame pour comparer les prédictions et les références\n",
    "resultats = pd.DataFrame({\n",
    "    'Titre': X_test,\n",
    "    'Categorie Prédite': y_pred\n",
    "})\n",
    "\n",
    "# Réinitialisation de l'index pour une meilleure lisibilité\n",
    "resultats.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Affichage du tableau des résultats\n",
    "print(resultats)\n",
    "\n",
    "# Optionnel: Sauvegarder le tableau dans un fichier CSV\n",
    "resultats.to_csv('../data/result_word2vec.csv', index=False)\n",
    "\n",
    "y_true = df_test['type']\n",
    "precision = accuracy_score(y_true, y_pred)\n",
    "print(f'Précision du modèle : {precision} \\n -----------------------------\\n')\n",
    "\n",
    "# Génération d'un rapport de classification\n",
    "rapport_classification = classification_report(y_true, y_pred)\n",
    "print('Rapport de classification :\\n', rapport_classification)\n",
    "\n",
    "rapport_df = pd.read_fwf(StringIO(rapport_classification), delimiter=';', header=0)\n",
    "rapport_df.to_csv(f'../data/result/result_tfid_{now}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
