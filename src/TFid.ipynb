{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "797d9b75-c226-409e-98d2-164b5cc2cb4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc58d17a-76c1-4500-bb2a-7cde864d45d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Titre Categorie Prédite\n",
      "0                          Roulé à la confiture de lait           Dessert\n",
      "1                                Croissants aux amandes           Dessert\n",
      "2     Quinoa Phileas (aux légumes croquants et sauci...    Plat principal\n",
      "3                   Magret de canard à la crème de mûre    Plat principal\n",
      "4     St-Jacques a la sauce aux huitres et aux asperges            Entrée\n",
      "...                                                 ...               ...\n",
      "1383             Galettes de pommes de terre aux navets    Plat principal\n",
      "1384  Terrine d'aubergines au thon de Nadine (4ème r...            Entrée\n",
      "1385              Gateau aux amandes et fleur d'oranger           Dessert\n",
      "1386                               Cailles au vin rouge    Plat principal\n",
      "1387  Gratin de pâtes au boeuf, courgettes et mascar...    Plat principal\n",
      "\n",
      "[1388 rows x 2 columns]\n",
      "Précision du modèle : 0.8141210374639769 \n",
      " -----------------------------\n",
      "\n",
      "Rapport de classification :\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       Dessert       0.93      0.92      0.92       407\n",
      "        Entrée       0.68      0.63      0.66       337\n",
      "Plat principal       0.81      0.84      0.82       644\n",
      "\n",
      "      accuracy                           0.81      1388\n",
      "     macro avg       0.81      0.80      0.80      1388\n",
      "  weighted avg       0.81      0.81      0.81      1388\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from io import StringIO\n",
    "import datetime\n",
    "now = datetime.datetime.now().strftime(format=\"%Y-%m-%d_%H-%M\")\n",
    "\n",
    "# Lecture du fichier CSV\n",
    "df_train = pd.read_csv('../data/train-sep.csv')\n",
    "\n",
    "# Séparation des données et prétraitement\n",
    "X_train = df_train['titre']\n",
    "y_train = df_train['type']\n",
    "\n",
    "# Création d'un pipeline et entraînement du modèle\n",
    "model = make_pipeline(TfidfVectorizer(), LinearSVC())\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "df_test = pd.read_csv('../data/test.csv')  # Replace 'test.csv' with the actual file name\n",
    "X_test = df_test['titre']\n",
    "\n",
    "# Prédiction sur l'ensemble de test\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Création d'un DataFrame pour comparer les prédictions et les références\n",
    "resultats = pd.DataFrame({\n",
    "    'Titre': X_test,\n",
    "    'Categorie Prédite': predictions\n",
    "})\n",
    "\n",
    "# Réinitialisation de l'index pour une meilleure lisibilité\n",
    "resultats.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Affichage du tableau des résultats\n",
    "print(resultats)\n",
    "\n",
    "# Sauvegarder le tableau dans un fichier CSV\n",
    "resultats.to_csv('../data/resultats_predictions.csv', index=False)\n",
    "\n",
    "y_true = df_test['type']\n",
    "precision = accuracy_score(y_true, predictions)\n",
    "print(f'Précision du modèle : {precision} \\n -----------------------------\\n')\n",
    "\n",
    "# Génération d'un rapport de classification\n",
    "rapport_classification = classification_report(y_true, predictions)\n",
    "print('Rapport de classification :\\n', rapport_classification)\n",
    "\n",
    "rapport_df = pd.read_fwf(StringIO(rapport_classification), delimiter=';', header=0)\n",
    "rapport_df.to_csv(f'../data/result/result_tfid_{now}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
