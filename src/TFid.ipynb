{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "797d9b75-c226-409e-98d2-164b5cc2cb4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc58d17a-76c1-4500-bb2a-7cde864d45d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Titre Categorie Réelle  \\\n",
      "0                 Croque monsieur au reblochon           Entrée   \n",
      "1                   Pâte à crêpes sans balance          Dessert   \n",
      "2                     Tomates farcies au boeuf   Plat principal   \n",
      "3             Quenelles de Polenta au beaufort           Entrée   \n",
      "4           Ballotines de volaille au chaource   Plat principal   \n",
      "...                                        ...              ...   \n",
      "1742  Pâte de pommes de terre de ma grand-mère   Plat principal   \n",
      "1743                 Crumble de poulet au thym   Plat principal   \n",
      "1744   Et un cheesecake white-chocolate ! Un !           Entrée   \n",
      "1745            Quenelles de poisson au cognac           Entrée   \n",
      "1746                            Lapin en sauce   Plat principal   \n",
      "\n",
      "     Categorie Prédite  \n",
      "0       Plat principal  \n",
      "1              Dessert  \n",
      "2       Plat principal  \n",
      "3               Entrée  \n",
      "4       Plat principal  \n",
      "...                ...  \n",
      "1742    Plat principal  \n",
      "1743    Plat principal  \n",
      "1744           Dessert  \n",
      "1745    Plat principal  \n",
      "1746    Plat principal  \n",
      "\n",
      "[1747 rows x 3 columns]\n",
      "Précision du modèle : 0.8196908986834573 \n",
      " -----------------------------\n",
      "\n",
      "Rapport de classification :\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       Dessert       0.92      0.92      0.92       508\n",
      "        Entrée       0.70      0.64      0.67       421\n",
      "Plat principal       0.81      0.85      0.83       818\n",
      "\n",
      "      accuracy                           0.82      1747\n",
      "     macro avg       0.81      0.80      0.81      1747\n",
      "  weighted avg       0.82      0.82      0.82      1747\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from io import StringIO\n",
    "\n",
    "# Lecture du fichier CSV\n",
    "df = pd.read_csv('../data/train-sep.csv')\n",
    "\n",
    "# Séparation des données et prétraitement\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['titre'], df['type'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Création d'un pipeline et entraînement du modèle\n",
    "model = make_pipeline(TfidfVectorizer(), LinearSVC())\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prédiction sur l'ensemble de test\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Création d'un DataFrame pour comparer les prédictions et les références\n",
    "resultats = pd.DataFrame({\n",
    "    'Titre': X_test,\n",
    "    'Categorie Réelle': y_test,\n",
    "    'Categorie Prédite': predictions\n",
    "})\n",
    "\n",
    "# Réinitialisation de l'index pour une meilleure lisibilité\n",
    "resultats.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Affichage du tableau des résultats\n",
    "print(resultats)\n",
    "\n",
    "# Optionnel: Sauvegarder le tableau dans un fichier CSV\n",
    "resultats.to_csv('../data/resultats_predictions.csv', index=False)\n",
    "\n",
    "precision = accuracy_score(y_test, predictions)\n",
    "print(f'Précision du modèle : {precision} \\n -----------------------------\\n')\n",
    "\n",
    "# Génération d'un rapport de classification\n",
    "rapport_classification = classification_report(y_test, predictions)\n",
    "print('Rapport de classification :\\n', rapport_classification)\n",
    "\n",
    "rapport_df = pd.read_fwf(StringIO(rapport_classification), delimiter=';', header=0)\n",
    "rapport_df.to_csv('../data/result_tfid.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
