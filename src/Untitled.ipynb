{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "797d9b75-c226-409e-98d2-164b5cc2cb4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc58d17a-76c1-4500-bb2a-7cde864d45d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Titre Categorie Réelle  \\\n",
      "0     Rissois aux crevettes (petits beignets du Port...           Entrée   \n",
      "1                                  Terrine aux fromages           Entrée   \n",
      "2                                          Gâteau Irene          Dessert   \n",
      "3                            Mousse de carottes au thon           Entrée   \n",
      "4                              Tarte aux figues et noix          Dessert   \n",
      "...                                                 ...              ...   \n",
      "1742             Matefaim ( beignets)  aux fines herbes   Plat principal   \n",
      "1743                        Le bourguignon de mon papa!   Plat principal   \n",
      "1744                       Quiche à la crème et au thon   Plat principal   \n",
      "1745                           Saumon et panais express   Plat principal   \n",
      "1746     Daube de poulpe aux carottes et tomates rapide   Plat principal   \n",
      "\n",
      "     Categorie Prédite  \n",
      "0       Plat principal  \n",
      "1               Entrée  \n",
      "2              Dessert  \n",
      "3               Entrée  \n",
      "4              Dessert  \n",
      "...                ...  \n",
      "1742            Entrée  \n",
      "1743    Plat principal  \n",
      "1744            Entrée  \n",
      "1745    Plat principal  \n",
      "1746            Entrée  \n",
      "\n",
      "[1747 rows x 3 columns]\n",
      "Précision du modèle : 0.8202633085289067\n",
      "Rapport de classification :\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       Dessert       0.91      0.93      0.92       534\n",
      "        Entrée       0.69      0.64      0.66       405\n",
      "Plat principal       0.82      0.84      0.83       808\n",
      "\n",
      "      accuracy                           0.82      1747\n",
      "     macro avg       0.81      0.80      0.80      1747\n",
      "  weighted avg       0.82      0.82      0.82      1747\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aa/Library/Python/3.9/lib/python/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Lecture du fichier CSV\n",
    "df = pd.read_csv('train-sep.csv')\n",
    "\n",
    "# Séparation des données et prétraitement\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['titre'], df['type'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Création d'un pipeline et entraînement du modèle\n",
    "model = make_pipeline(TfidfVectorizer(), LinearSVC())\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prédiction sur l'ensemble de test\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Création d'un DataFrame pour comparer les prédictions et les références\n",
    "resultats = pd.DataFrame({\n",
    "    'Titre': X_test,\n",
    "    'Categorie Réelle': y_test,\n",
    "    'Categorie Prédite': predictions\n",
    "})\n",
    "\n",
    "# Réinitialisation de l'index pour une meilleure lisibilité\n",
    "resultats.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Affichage du tableau des résultats\n",
    "print(resultats)\n",
    "\n",
    "# Optionnel: Sauvegarder le tableau dans un fichier CSV\n",
    "resultats.to_csv('resultats_predictions.csv', index=False)\n",
    "\n",
    "precision = accuracy_score(y_test, predictions)\n",
    "print(f'Précision du modèle : {precision}')\n",
    "\n",
    "# Génération d'un rapport de classification\n",
    "rapport_classification = classification_report(y_test, predictions)\n",
    "print('Rapport de classification :\\n', rapport_classification)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
